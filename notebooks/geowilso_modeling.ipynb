{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd3f71bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from tensorflow.keras import utils\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
    "from tensorflow.keras import losses, models, optimizers\n",
    "from keras.activations import relu, softmax\n",
    "from keras.layers import (Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten, Dropout,\n",
    "                          GlobalMaxPool2D, MaxPool2D, concatenate, Activation, Input, Dense)\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Other  \n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "import scipy\n",
    "from scipy.stats import skew\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob \n",
    "import os\n",
    "import sys\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import warnings\n",
    "# ignore warnings \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f24df011",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Data Augmentation method   \n",
    "'''\n",
    "def speedNpitch(data):\n",
    "    \"\"\"\n",
    "    Speed and Pitch Tuning.\n",
    "    \"\"\"\n",
    "    # you can change low and high here\n",
    "    length_change = np.random.uniform(low=0.8, high = 1)\n",
    "    speed_fac = 1.2  / length_change # try changing 1.0 to 2.0 ... =D\n",
    "    tmp = np.interp(np.arange(0,len(data),speed_fac),np.arange(0,len(data)),data)\n",
    "    minlen = min(data.shape[0], tmp.shape[0])\n",
    "    data *= 0\n",
    "    data[0:minlen] = tmp[0:minlen]\n",
    "    return data\n",
    "\n",
    "'''\n",
    "2. Extracting the MFCC feature as an image (Matrix format).  \n",
    "'''\n",
    "def prepare_data(df, n, aug, mfcc):\n",
    "    X = np.empty(shape=(df.shape[0], n, 216, 1))\n",
    "    input_length = sampling_rate * audio_duration\n",
    "    \n",
    "    cnt = 0\n",
    "    for fname in tqdm(df.path):\n",
    "        file_path = fname\n",
    "        data, _ = librosa.load(file_path, sr=sampling_rate\n",
    "                               ,res_type=\"kaiser_fast\"\n",
    "                               ,duration=2.5\n",
    "                               ,offset=0.5\n",
    "                              )\n",
    "\n",
    "        # Random offset / Padding\n",
    "        if len(data) > input_length:\n",
    "            max_offset = len(data) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            data = data[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(data):\n",
    "                max_offset = input_length - len(data)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "            data = np.pad(data, (offset, int(input_length) - len(data) - offset), \"constant\")\n",
    "\n",
    "        # Augmentation? \n",
    "        if aug == 1:\n",
    "            data = speedNpitch(data)\n",
    "        \n",
    "        # which feature?\n",
    "        if mfcc == 1:\n",
    "            # MFCC extraction \n",
    "            MFCC = librosa.feature.mfcc(data, sr=sampling_rate, n_mfcc=n_mfcc)\n",
    "            MFCC = np.expand_dims(MFCC, axis=-1)\n",
    "            X[cnt,] = MFCC\n",
    "            \n",
    "        else:\n",
    "            # Log-melspectogram\n",
    "            melspec = librosa.feature.melspectrogram(data, n_mels = n_melspec)   \n",
    "            logspec = librosa.amplitude_to_db(melspec)\n",
    "            logspec = np.expand_dims(logspec, axis=-1)\n",
    "            X[cnt,] = logspec\n",
    "            \n",
    "        cnt += 1\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "'''\n",
    "3. Confusion matrix plot \n",
    "'''        \n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    '''Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    '''\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    \n",
    "    \n",
    "'''\n",
    "# 4. Create the 2D CNN model \n",
    "'''\n",
    "def get_2d_conv_model(n):\n",
    "    ''' Create a standard deep 2D convolutional neural network'''\n",
    "    nclass = 14\n",
    "    inp = Input(shape=(n,216,1))  #2D matrix of 30 MFCC bands by 216 audio length.\n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    \n",
    "    opt = optimizers.Adam(0.001)\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "'''\n",
    "# 5. Other functions \n",
    "'''\n",
    "class get_results:\n",
    "    '''\n",
    "    We're going to create a class (blueprint template) for generating the results based on the various model approaches. \n",
    "    So instead of repeating the functions each time, we assign the results into on object with its associated variables \n",
    "    depending on each combination:\n",
    "        1) MFCC with no augmentation  \n",
    "        2) MFCC with augmentation \n",
    "        3) Logmelspec with no augmentation \n",
    "        4) Logmelspec with augmentation\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, model_history, model ,X_test, y_test, labels):\n",
    "        self.model_history = model_history\n",
    "        self.model = model\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test             \n",
    "        self.labels = labels\n",
    "\n",
    "    def create_plot(self, model_history):\n",
    "        '''Check the logloss of both train and validation, make sure they are close and have plateau'''\n",
    "        plt.plot(model_history.history['loss'])\n",
    "        plt.plot(model_history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    def create_results(self, model):\n",
    "        '''predict on test set and get accuracy results'''\n",
    "        opt = optimizers.Adam(0.001)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        score = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "    def confusion_results(self, X_test, y_test, labels, model):\n",
    "        '''plot confusion matrix results'''\n",
    "        preds = model.predict(X_test, \n",
    "                                 batch_size=16, \n",
    "                                 verbose=2)\n",
    "        preds=preds.argmax(axis=1)\n",
    "        preds = preds.astype(int).flatten()\n",
    "        preds = (lb.inverse_transform((preds)))\n",
    "\n",
    "        actual = y_test.argmax(axis=1)\n",
    "        actual = actual.astype(int).flatten()\n",
    "        actual = (lb.inverse_transform((actual)))\n",
    "\n",
    "        classes = labels\n",
    "        classes.sort()    \n",
    "\n",
    "        c = confusion_matrix(actual, preds)\n",
    "        print_confusion_matrix(c, class_names = classes)\n",
    "    \n",
    "    def accuracy_results_gender(self, X_test, y_test, labels, model):\n",
    "        '''Print out the accuracy score and confusion matrix heat map of the Gender classification results'''\n",
    "    \n",
    "        preds = model.predict(X_test, \n",
    "                         batch_size=16, \n",
    "                         verbose=2)\n",
    "        preds=preds.argmax(axis=1)\n",
    "        preds = preds.astype(int).flatten()\n",
    "        preds = (lb.inverse_transform((preds)))\n",
    "\n",
    "        actual = y_test.argmax(axis=1)\n",
    "        actual = actual.astype(int).flatten()\n",
    "        actual = (lb.inverse_transform((actual)))\n",
    "        \n",
    "        # print(accuracy_score(actual, preds))\n",
    "        \n",
    "        actual = pd.DataFrame(actual).replace({'female_angry':'female'\n",
    "                   , 'female_disgust':'female'\n",
    "                   , 'female_fear':'female'\n",
    "                   , 'female_happy':'female'\n",
    "                   , 'female_sad':'female'\n",
    "                   , 'female_surprise':'female'\n",
    "                   , 'female_neutral':'female'\n",
    "                   , 'male_angry':'male'\n",
    "                   , 'male_fear':'male'\n",
    "                   , 'male_happy':'male'\n",
    "                   , 'male_sad':'male'\n",
    "                   , 'male_surprise':'male'\n",
    "                   , 'male_neutral':'male'\n",
    "                   , 'male_disgust':'male'\n",
    "                  })\n",
    "        preds = pd.DataFrame(preds).replace({'female_angry':'female'\n",
    "               , 'female_disgust':'female'\n",
    "               , 'female_fear':'female'\n",
    "               , 'female_happy':'female'\n",
    "               , 'female_sad':'female'\n",
    "               , 'female_surprise':'female'\n",
    "               , 'female_neutral':'female'\n",
    "               , 'male_angry':'male'\n",
    "               , 'male_fear':'male'\n",
    "               , 'male_happy':'male'\n",
    "               , 'male_sad':'male'\n",
    "               , 'male_surprise':'male'\n",
    "               , 'male_neutral':'male'\n",
    "               , 'male_disgust':'male'\n",
    "              })\n",
    "\n",
    "        classes = actual.loc[:,0].unique() \n",
    "        classes.sort()    \n",
    "\n",
    "        c = confusion_matrix(actual, preds)\n",
    "        print(accuracy_score(actual, preds))\n",
    "        print_confusion_matrix(c, class_names = classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0120009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1001_DFA_ANG_XX.wav', '1001_DFA_DIS_XX.wav', '1001_DFA_FEA_XX.wav', '1001_DFA_HAP_XX.wav', '1001_DFA_NEU_XX.wav', '1001_DFA_SAD_XX.wav', '1001_IEO_ANG_HI.wav', '1001_IEO_ANG_LO.wav', '1001_IEO_ANG_MD.wav', '1001_IEO_DIS_HI.wav']\n"
     ]
    }
   ],
   "source": [
    "CREMA = '../raw_data/wav_files/'\n",
    "dir_list = os.listdir(CREMA)\n",
    "dir_list.sort()\n",
    "print(dir_list[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64ebd205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male_angry        671\n",
       "male_disgust      671\n",
       "male_fear         671\n",
       "male_happy        671\n",
       "male_sad          671\n",
       "female_angry      600\n",
       "female_disgust    600\n",
       "female_fear       600\n",
       "female_happy      600\n",
       "female_sad        600\n",
       "male_neutral      575\n",
       "female_neutral    512\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender = []\n",
    "emotion = []\n",
    "path = []\n",
    "female = [1002,1003,1004,1006,1007,1008,1009,1010,1012,1013,1018,1020,1021,1024,1025,1028,1029,1030,1037,1043,1046,1047,1049,\n",
    "          1052,1053,1054,1055,1056,1058,1060,1061,1063,1072,1073,1074,1075,1076,1078,1079,1082,1084,1089,1091]\n",
    "\n",
    "for i in dir_list: \n",
    "    part = i.split('_')\n",
    "    if int(part[0]) in female:\n",
    "        temp = 'female'\n",
    "    else:\n",
    "        temp = 'male'\n",
    "    gender.append(temp)\n",
    "    if part[2] == 'SAD' and temp == 'male':\n",
    "        emotion.append('male_sad')\n",
    "    elif part[2] == 'ANG' and temp == 'male':\n",
    "        emotion.append('male_angry')\n",
    "    elif part[2] == 'DIS' and temp == 'male':\n",
    "        emotion.append('male_disgust')\n",
    "    elif part[2] == 'FEA' and temp == 'male':\n",
    "        emotion.append('male_fear')\n",
    "    elif part[2] == 'HAP' and temp == 'male':\n",
    "        emotion.append('male_happy')\n",
    "    elif part[2] == 'NEU' and temp == 'male':\n",
    "        emotion.append('male_neutral')\n",
    "    elif part[2] == 'SAD' and temp == 'female':\n",
    "        emotion.append('female_sad')\n",
    "    elif part[2] == 'ANG' and temp == 'female':\n",
    "        emotion.append('female_angry')\n",
    "    elif part[2] == 'DIS' and temp == 'female':\n",
    "        emotion.append('female_disgust')\n",
    "    elif part[2] == 'FEA' and temp == 'female':\n",
    "        emotion.append('female_fear')\n",
    "    elif part[2] == 'HAP' and temp == 'female':\n",
    "        emotion.append('female_happy')\n",
    "    elif part[2] == 'NEU' and temp == 'female':\n",
    "        emotion.append('female_neutral')\n",
    "    else:\n",
    "        emotion.append('Unknown')\n",
    "    path.append(CREMA + i)\n",
    "    \n",
    "CREMA_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "CREMA_df['source'] = 'CREMA'\n",
    "CREMA_df = pd.concat([CREMA_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "CREMA_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfe937bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = CREMA_df.groupby('labels')\n",
    "CREMA_sample = group.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26440e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 360/360 [00:17<00:00, 20.16it/s]\n"
     ]
    }
   ],
   "source": [
    "sampling_rate=44100\n",
    "audio_duration=2.5\n",
    "n_mfcc = 30\n",
    "mfcc = prepare_data(CREMA_sample, n = n_mfcc, aug = 0, mfcc = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "299bb00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 30, 216, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21eda2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 12) and (None, 14) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Build CNN model \u001b[39;00m\n\u001b[1;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m get_2d_conv_model(n\u001b[38;5;241m=\u001b[39mn_mfcc)\n\u001b[0;32m---> 24\u001b[0m model_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 12) and (None, 14) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# Split between train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(mfcc\n",
    "                                                    , CREMA_sample.labels\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "\n",
    "\n",
    "# one hot encode the target \n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "# Normalization as per the standard NN process\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "\n",
    "# Build CNN model \n",
    "model = get_2d_conv_model(n=n_mfcc)\n",
    "model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                    batch_size=16, verbose = 2, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf88a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_results(model_history,model,X_test,y_test, ref.labels.unique())\n",
    "results.create_plot(model_history)\n",
    "results.create_results(model)\n",
    "results.confusion_results(X_test, y_test, ref.labels.unique(), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d17a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
