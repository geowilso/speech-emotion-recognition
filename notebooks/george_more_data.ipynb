{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a133d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 21:51:46.083177: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-03 21:51:46.083280: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33c7ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "crema = '/home/geowilso/code/geowilso/speech-emotion-recognition/raw_data/wav_files/crema/'\n",
    "tess = '/home/geowilso/code/geowilso/speech-emotion-recognition/raw_data/wav_files/tess/'\n",
    "ravdess = '/home/geowilso/code/geowilso/speech-emotion-recognition/raw_data/wav_files/ravdess/'\n",
    "savee = '/home/geowilso/code/geowilso/speech-emotion-recognition/raw_data/wav_files/savee/'\n",
    "emodb = '/home/geowilso/code/geowilso/speech-emotion-recognition/raw_data/wav_files/emodb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b6ab8e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_directory_list = os.listdir(crema)\n",
    "\n",
    "gender = []\n",
    "emotion = []\n",
    "path = []\n",
    "female = [1002,1003,1004,1006,1007,1008,1009,1010,1012,1013,1018,1020,1021,1024,1025,1028,1029,1030,1037,1043,1046,1047,1049,\n",
    "          1052,1053,1054,1055,1056,1058,1060,1061,1063,1072,1073,1074,1075,1076,1078,1079,1082,1084,1089,1091]\n",
    "\n",
    "for i in crema_directory_list: \n",
    "    part = i.split('_')\n",
    "    if int(part[0]) in female:\n",
    "        temp = 'female'\n",
    "    else:\n",
    "        temp = 'male'\n",
    "    gender.append(temp)\n",
    "    \n",
    "    if part[2] == 'SAD':\n",
    "        emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        emotion.append('neutral')\n",
    "    else:\n",
    "        emotion.append('unknown')\n",
    "    path.append(crema + i)\n",
    "    \n",
    "crema_df = pd.DataFrame(emotion, columns = ['emotion'])\n",
    "crema_df = pd.concat([crema_df,pd.DataFrame(gender, columns = ['gender'])],axis=1)\n",
    "crema_df = pd.concat([crema_df,pd.DataFrame(path, columns = ['path'])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ae22108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combo(df):\n",
    "    return f'{df[1]}_{df[0]}'\n",
    "\n",
    "def sad(x):\n",
    "    return 1 if x.lower() == 'sad' else 0\n",
    "\n",
    "def angry(x):\n",
    "    return 1 if x.lower() == 'angry' else 0\n",
    "\n",
    "def disgust(x):\n",
    "    return 1 if x.lower() == 'disgust' else 0\n",
    "\n",
    "def fear(x):\n",
    "    return 1 if x.lower() == 'fear' else 0\n",
    "\n",
    "def happy(x):\n",
    "    return 1 if x.lower() == 'happy' else 0\n",
    "\n",
    "def neutral(x):\n",
    "    return 1 if x.lower() == 'neutral' else 0\n",
    "\n",
    "def pos_or_neg(x):\n",
    "    if x == 'happy' or x == 'surprise':\n",
    "        return 'positive'\n",
    "    elif x == 'neutral':\n",
    "        return x\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8e062cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_df['source'] = 'crema'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "786bffc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sad</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion  gender                                               path source\n",
       "0     fear  female  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "1  disgust    male  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "2      sad    male  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "3    happy  female  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "4    angry    male  /home/geowilso/code/geowilso/speech-emotion-re...  crema"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c953244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "afdd19dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(savee)\n",
    "\n",
    "# parse the filename to get the emotions\n",
    "emotion=[]\n",
    "path = []\n",
    "for i in dir_list:\n",
    "    if i[-8:-6]=='_a':\n",
    "        emotion.append('angry')\n",
    "    elif i[-8:-6]=='_d':\n",
    "        emotion.append('disgust')\n",
    "    elif i[-8:-6]=='_f':\n",
    "        emotion.append('fear')\n",
    "    elif i[-8:-6]=='_h':\n",
    "        emotion.append('happy')\n",
    "    elif i[-8:-6]=='_n':\n",
    "        emotion.append('neutral')\n",
    "    elif i[-8:-6]=='sa':\n",
    "        emotion.append('sad')\n",
    "    elif i[-8:-6]=='su':\n",
    "        emotion.append('surprise')\n",
    "    else:\n",
    "        emotion.append('error') \n",
    "    path.append(savee + i)\n",
    "    \n",
    "# Now check out the label count distribution \n",
    "savee_df = pd.DataFrame(emotion, columns = ['emotion'])\n",
    "savee_df['source'] = 'savee'\n",
    "savee_df = pd.concat([savee_df, pd.DataFrame(path, columns = ['path'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f542707",
   "metadata": {},
   "outputs": [],
   "source": [
    "savee_df['gender'] = 'male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2ebf729d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>source</th>\n",
       "      <th>path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>savee</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>savee</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>savee</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>savee</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy</td>\n",
       "      <td>savee</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion source                                               path gender\n",
       "0     fear  savee  /home/geowilso/code/geowilso/speech-emotion-re...   male\n",
       "1  disgust  savee  /home/geowilso/code/geowilso/speech-emotion-re...   male\n",
       "2  disgust  savee  /home/geowilso/code/geowilso/speech-emotion-re...   male\n",
       "3  neutral  savee  /home/geowilso/code/geowilso/speech-emotion-re...   male\n",
       "4    happy  savee  /home/geowilso/code/geowilso/speech-emotion-re...   male"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "86d72e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(ravdess)\n",
    "dir_list.sort()\n",
    "\n",
    "emotion = []\n",
    "gender = []\n",
    "path = []\n",
    "for i in dir_list:\n",
    "    fname = os.listdir(ravdess + i)\n",
    "    for f in fname:\n",
    "        part = f.split('.')[0].split('-')\n",
    "        emotion.append(int(part[2]))\n",
    "        temp = int(part[6])\n",
    "        if temp%2 == 0:\n",
    "            temp = \"female\"\n",
    "        else:\n",
    "            temp = \"male\"\n",
    "        gender.append(temp)\n",
    "        path.append(ravdess + i + '/' + f)\n",
    "        \n",
    "ravdess_df = pd.DataFrame(emotion)\n",
    "ravdess_df = ravdess_df.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "ravdess_df = pd.concat([pd.DataFrame(gender),ravdess_df],axis=1)\n",
    "ravdess_df.columns = ['gender','emotion']\n",
    "ravdess_df['source'] = 'ravdess'  \n",
    "ravdess_df = pd.concat([ravdess_df,pd.DataFrame(path, columns = ['path'])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a5c12af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>source</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ravdess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>fear</td>\n",
       "      <td>ravdess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>surprise</td>\n",
       "      <td>ravdess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>angry</td>\n",
       "      <td>ravdess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>fear</td>\n",
       "      <td>ravdess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>female</td>\n",
       "      <td>surprise</td>\n",
       "      <td>ravdess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "      <td>ravdess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>female</td>\n",
       "      <td>surprise</td>\n",
       "      <td>ravdess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>female</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ravdess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>female</td>\n",
       "      <td>fear</td>\n",
       "      <td>ravdess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   emotion   source  \\\n",
       "0       male   neutral  ravdess   \n",
       "1       male      fear  ravdess   \n",
       "2       male  surprise  ravdess   \n",
       "3       male     angry  ravdess   \n",
       "4       male      fear  ravdess   \n",
       "...      ...       ...      ...   \n",
       "1435  female  surprise  ravdess   \n",
       "1436  female     angry  ravdess   \n",
       "1437  female  surprise  ravdess   \n",
       "1438  female   neutral  ravdess   \n",
       "1439  female      fear  ravdess   \n",
       "\n",
       "                                                   path  \n",
       "0     /home/geowilso/code/geowilso/speech-emotion-re...  \n",
       "1     /home/geowilso/code/geowilso/speech-emotion-re...  \n",
       "2     /home/geowilso/code/geowilso/speech-emotion-re...  \n",
       "3     /home/geowilso/code/geowilso/speech-emotion-re...  \n",
       "4     /home/geowilso/code/geowilso/speech-emotion-re...  \n",
       "...                                                 ...  \n",
       "1435  /home/geowilso/code/geowilso/speech-emotion-re...  \n",
       "1436  /home/geowilso/code/geowilso/speech-emotion-re...  \n",
       "1437  /home/geowilso/code/geowilso/speech-emotion-re...  \n",
       "1438  /home/geowilso/code/geowilso/speech-emotion-re...  \n",
       "1439  /home/geowilso/code/geowilso/speech-emotion-re...  \n",
       "\n",
       "[1440 rows x 4 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ravdess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "48b7a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(tess)\n",
    "dir_list.sort()\n",
    "\n",
    "path = []\n",
    "emotion = []\n",
    "\n",
    "for i in dir_list:\n",
    "    fname = os.listdir(tess + i)\n",
    "    for f in fname:\n",
    "        if i == 'OAF_angry' or i == 'YAF_angry':\n",
    "            emotion.append('angry')\n",
    "        elif i == 'OAF_disgust' or i == 'YAF_disgust':\n",
    "            emotion.append('disgust')\n",
    "        elif i == 'OAF_Fear' or i == 'YAF_fear':\n",
    "            emotion.append('fear')\n",
    "        elif i == 'OAF_happy' or i == 'YAF_happy':\n",
    "            emotion.append('happy')\n",
    "        elif i == 'OAF_neutral' or i == 'YAF_neutral':\n",
    "            emotion.append('neutral')                                \n",
    "        elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\n",
    "            emotion.append('surprise')               \n",
    "        elif i == 'OAF_Sad' or i == 'YAF_sad':\n",
    "            emotion.append('sad')\n",
    "        else:\n",
    "            emotion.append('Unknown')\n",
    "        path.append(tess + i + \"/\" + f)\n",
    "\n",
    "tess_df = pd.DataFrame(emotion, columns = ['emotion'])\n",
    "tess_df['source'] = 'tess'\n",
    "tess_df = pd.concat([tess_df,pd.DataFrame(path, columns = ['path'])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e541ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_df['gender'] = 'female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e709d6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>source</th>\n",
       "      <th>path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>tess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>tess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>tess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>tess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fear</td>\n",
       "      <td>tess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>sad</td>\n",
       "      <td>tess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>sad</td>\n",
       "      <td>tess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>sad</td>\n",
       "      <td>tess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>sad</td>\n",
       "      <td>tess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>sad</td>\n",
       "      <td>tess</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion source                                               path  gender\n",
       "0       fear   tess  /home/geowilso/code/geowilso/speech-emotion-re...  female\n",
       "1       fear   tess  /home/geowilso/code/geowilso/speech-emotion-re...  female\n",
       "2       fear   tess  /home/geowilso/code/geowilso/speech-emotion-re...  female\n",
       "3       fear   tess  /home/geowilso/code/geowilso/speech-emotion-re...  female\n",
       "4       fear   tess  /home/geowilso/code/geowilso/speech-emotion-re...  female\n",
       "...      ...    ...                                                ...     ...\n",
       "2795     sad   tess  /home/geowilso/code/geowilso/speech-emotion-re...  female\n",
       "2796     sad   tess  /home/geowilso/code/geowilso/speech-emotion-re...  female\n",
       "2797     sad   tess  /home/geowilso/code/geowilso/speech-emotion-re...  female\n",
       "2798     sad   tess  /home/geowilso/code/geowilso/speech-emotion-re...  female\n",
       "2799     sad   tess  /home/geowilso/code/geowilso/speech-emotion-re...  female\n",
       "\n",
       "[2800 rows x 4 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5ec62ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.concat([crema_df,tess_df,ravdess_df,savee_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ad24c815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sad</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>neutral</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>disgust</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>angry</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>neutral</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>happy</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11510 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion  gender                                               path source\n",
       "0       fear  female  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "1    disgust    male  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "2        sad    male  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "3      happy  female  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "4      angry    male  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "..       ...     ...                                                ...    ...\n",
       "474  neutral    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "475  disgust    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "476    angry    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "478  neutral    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "479    happy    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "\n",
       "[11510 rows x 4 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5c3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7098631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "229e799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets[targets['emotion']!='surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8afca7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Count of Gender', size=12)\n",
    "sns.countplot(targets.gender)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Gender', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9baf96f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Count of Emotions', size=16)\n",
    "sns.countplot(targets.emotion)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ef533ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'disgust': 0, 'happy': 1, 'sad': 2, 'neutral': 3, 'fear': 4, 'angry': 5}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c7951646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sad</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>neutral</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>disgust</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>angry</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>neutral</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>happy</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11510 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion  gender                                               path source\n",
       "0       fear  female  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "1    disgust    male  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "2        sad    male  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "3      happy  female  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "4      angry    male  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "..       ...     ...                                                ...    ...\n",
       "474  neutral    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "475  disgust    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "476    angry    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "478  neutral    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "479    happy    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "\n",
       "[11510 rows x 4 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {'disgust':0,'happy':1,'sad':2,'neutral':3,'fear':4,'angry':5}\n",
    "targets.replace({'Emotions':labels},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a51e1838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n"
     ]
    }
   ],
   "source": [
    "num_mfcc=13\n",
    "n_fft=2048\n",
    "hop_length=512\n",
    "SAMPLE_RATE = 22050\n",
    "data = {\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "for i in range(11510):\n",
    "    data['labels'].append(targets.iloc[i,0])\n",
    "    signal, sample_rate = librosa.load(targets.iloc[i,2], sr=SAMPLE_RATE)\n",
    "    mfcc = librosa.feature.mfcc(signal, sample_rate, n_mfcc=13, n_fft=2048, hop_length=512)\n",
    "    mfcc = mfcc.T\n",
    "    data[\"mfcc\"].append(np.asarray(mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b83ad8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(data['mfcc'])\n",
    "y = np.asarray(data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d434759e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11510, 308, 13)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d1a7a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a75eeb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(LSTM(64))\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9d51c74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, None, 128)         72704     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,662\n",
      "Trainable params: 126,662\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create network\n",
    "input_shape = (None,13)\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# compile model\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimiser,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a7d71c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 18:29:41.399242: W tensorflow/core/framework/op_kernel.cc:1722] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'Cast_1' defined at (most recent call last):\n    File \"/home/geowilso/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/geowilso/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_5326/2197069139.py\", line 1, in <module>\n      history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/metrics.py\", line 720, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_1'\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_37916]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [177]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_validation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'Cast_1' defined at (most recent call last):\n    File \"/home/geowilso/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/geowilso/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_5326/2197069139.py\", line 1, in <module>\n      history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/geowilso/.pyenv/versions/3.8.12/envs/speech-emotion-recognition/lib/python3.8/site-packages/keras/metrics.py\", line 720, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_1'\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_37916]"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69cb2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc3d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: \",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9421e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9fa10256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11510"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets['path'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "93b50952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>disgust</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>disgust</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>disgust</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>disgust</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>crema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>disgust</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>disgust</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>disgust</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>disgust</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>disgust</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/geowilso/code/geowilso/speech-emotion-re...</td>\n",
       "      <td>savee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1923 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion  gender                                               path source\n",
       "1    disgust    male  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "7    disgust    male  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "11   disgust  female  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "16   disgust    male  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "22   disgust  female  /home/geowilso/code/geowilso/speech-emotion-re...  crema\n",
       "..       ...     ...                                                ...    ...\n",
       "437  disgust    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "449  disgust    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "463  disgust    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "468  disgust    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "475  disgust    male  /home/geowilso/code/geowilso/speech-emotion-re...  savee\n",
       "\n",
       "[1923 rows x 4 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[targets['emotion']=='disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "1923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "95c12841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12162"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_df.shape[0]+tess_df.shape[0]+ravdess_df.shape[0]+savee_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "41971084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800, 4)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0b256746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 4)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ravdess_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "703575a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 4)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savee_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "919e484f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11510, 4)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "618fe2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fear', 'disgust', 'sad', 'happy', 'angry', 'neutral', 'surprise'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = pd.concat([crema_df,tess_df,ravdess_df,savee_df])\n",
    "targets['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1c55eb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12162, 4)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b427c6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7664, 4)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = targets[targets['emotion']!='surprise']\n",
    "targets = targets[targets['emotion']!='fear']\n",
    "targets = targets[targets['emotion']!='disgust']\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "targ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
